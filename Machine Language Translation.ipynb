{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cccc4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "batch_size =64\n",
    "epochs=100\n",
    "latent_dim=256\n",
    "min_samples=10000\n",
    "data_path='fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a53cb551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizng Data\n",
    "input_texts=[]\n",
    "target_texts=[]\n",
    "input_chars=set()\n",
    "target_chars=set()\n",
    "with open(data_path,'r',encoding='utf-8') as f:\n",
    "    lines=f.read().split('\\n')\n",
    "for lines in lines[: min(min_samples,len(lines)-1)]:\n",
    "    input_text,target_text,_=lines.split('\\t')\n",
    "    target_text='\\t'+target_text+'\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_chars:\n",
    "            input_chars.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_chars:\n",
    "            target_chars.add(char)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff361f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chars=sorted(list(input_chars))\n",
    "target_chars=sorted(list(target_chars))\n",
    "num_encoder_tokens=len(input_chars)\n",
    "num_decoder_tokens=len(target_chars)\n",
    "max_encoder_seq_length=max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length=max([len(txt) for txt in target_texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34fe55db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 10000\n",
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 92\n",
      "Max sequence length for inputs: 15\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "print('Number of Samples:',len(input_texts))\n",
    "print(\"Number of unique input tokens:\",num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\",num_decoder_tokens)\n",
    "print('Max sequence length for inputs:',max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:',max_decoder_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8186451",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index=dict(\n",
    "[(char,i) for i , char in enumerate(input_chars)])\n",
    "target_token_index=dict(\n",
    "[(char,i) for i , char in enumerate(target_chars)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2e0c8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({' ': 0,\n",
       "  '!': 1,\n",
       "  '\"': 2,\n",
       "  '$': 3,\n",
       "  '%': 4,\n",
       "  '&': 5,\n",
       "  \"'\": 6,\n",
       "  ',': 7,\n",
       "  '-': 8,\n",
       "  '.': 9,\n",
       "  '0': 10,\n",
       "  '1': 11,\n",
       "  '2': 12,\n",
       "  '3': 13,\n",
       "  '5': 14,\n",
       "  '7': 15,\n",
       "  '8': 16,\n",
       "  '9': 17,\n",
       "  ':': 18,\n",
       "  '?': 19,\n",
       "  'A': 20,\n",
       "  'B': 21,\n",
       "  'C': 22,\n",
       "  'D': 23,\n",
       "  'E': 24,\n",
       "  'F': 25,\n",
       "  'G': 26,\n",
       "  'H': 27,\n",
       "  'I': 28,\n",
       "  'J': 29,\n",
       "  'K': 30,\n",
       "  'L': 31,\n",
       "  'M': 32,\n",
       "  'N': 33,\n",
       "  'O': 34,\n",
       "  'P': 35,\n",
       "  'Q': 36,\n",
       "  'R': 37,\n",
       "  'S': 38,\n",
       "  'T': 39,\n",
       "  'U': 40,\n",
       "  'V': 41,\n",
       "  'W': 42,\n",
       "  'Y': 43,\n",
       "  'a': 44,\n",
       "  'b': 45,\n",
       "  'c': 46,\n",
       "  'd': 47,\n",
       "  'e': 48,\n",
       "  'f': 49,\n",
       "  'g': 50,\n",
       "  'h': 51,\n",
       "  'i': 52,\n",
       "  'j': 53,\n",
       "  'k': 54,\n",
       "  'l': 55,\n",
       "  'm': 56,\n",
       "  'n': 57,\n",
       "  'o': 58,\n",
       "  'p': 59,\n",
       "  'q': 60,\n",
       "  'r': 61,\n",
       "  's': 62,\n",
       "  't': 63,\n",
       "  'u': 64,\n",
       "  'v': 65,\n",
       "  'w': 66,\n",
       "  'x': 67,\n",
       "  'y': 68,\n",
       "  'z': 69,\n",
       "  'é': 70},\n",
       " {'\\t': 0,\n",
       "  '\\n': 1,\n",
       "  ' ': 2,\n",
       "  '!': 3,\n",
       "  '%': 4,\n",
       "  '&': 5,\n",
       "  \"'\": 6,\n",
       "  '(': 7,\n",
       "  ')': 8,\n",
       "  ',': 9,\n",
       "  '-': 10,\n",
       "  '.': 11,\n",
       "  '0': 12,\n",
       "  '1': 13,\n",
       "  '2': 14,\n",
       "  '3': 15,\n",
       "  '5': 16,\n",
       "  '8': 17,\n",
       "  '9': 18,\n",
       "  ':': 19,\n",
       "  '?': 20,\n",
       "  'A': 21,\n",
       "  'B': 22,\n",
       "  'C': 23,\n",
       "  'D': 24,\n",
       "  'E': 25,\n",
       "  'F': 26,\n",
       "  'G': 27,\n",
       "  'H': 28,\n",
       "  'I': 29,\n",
       "  'J': 30,\n",
       "  'K': 31,\n",
       "  'L': 32,\n",
       "  'M': 33,\n",
       "  'N': 34,\n",
       "  'O': 35,\n",
       "  'P': 36,\n",
       "  'Q': 37,\n",
       "  'R': 38,\n",
       "  'S': 39,\n",
       "  'T': 40,\n",
       "  'U': 41,\n",
       "  'V': 42,\n",
       "  'Y': 43,\n",
       "  'a': 44,\n",
       "  'b': 45,\n",
       "  'c': 46,\n",
       "  'd': 47,\n",
       "  'e': 48,\n",
       "  'f': 49,\n",
       "  'g': 50,\n",
       "  'h': 51,\n",
       "  'i': 52,\n",
       "  'j': 53,\n",
       "  'k': 54,\n",
       "  'l': 55,\n",
       "  'm': 56,\n",
       "  'n': 57,\n",
       "  'o': 58,\n",
       "  'p': 59,\n",
       "  'q': 60,\n",
       "  'r': 61,\n",
       "  's': 62,\n",
       "  't': 63,\n",
       "  'u': 64,\n",
       "  'v': 65,\n",
       "  'w': 66,\n",
       "  'x': 67,\n",
       "  'y': 68,\n",
       "  'z': 69,\n",
       "  '\\xa0': 70,\n",
       "  '«': 71,\n",
       "  '»': 72,\n",
       "  'À': 73,\n",
       "  'Ç': 74,\n",
       "  'É': 75,\n",
       "  'Ê': 76,\n",
       "  'à': 77,\n",
       "  'â': 78,\n",
       "  'ç': 79,\n",
       "  'è': 80,\n",
       "  'é': 81,\n",
       "  'ê': 82,\n",
       "  'î': 83,\n",
       "  'ï': 84,\n",
       "  'ô': 85,\n",
       "  'ù': 86,\n",
       "  'û': 87,\n",
       "  'œ': 88,\n",
       "  '\\u2009': 89,\n",
       "  '’': 90,\n",
       "  '\\u202f': 91})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index,target_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f6a4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data=np.zeros((len(input_texts),max_encoder_seq_length,num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data=np.zeros((len(input_texts),max_decoder_seq_length,num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data=np.zeros((len(input_texts),max_decoder_seq_length,num_decoder_tokens), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56d85588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot representation\n",
    "for i ,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t ,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token_index[char]]=1\n",
    "    encoder_input_data[i,t+1:,input_token_index[char]]=1\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i,t,target_token_index[char]]=1\n",
    "        if t>0:\n",
    "            decoder_target_data[i,t-1,target_token_index[char]]=1\n",
    "    decoder_input_data[i,t+1:,target_token_index[' ']]=1\n",
    "    decoder_target_data[i,t:,target_token_index[' ']]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d60d5b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 71)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61426af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can hear you.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41b92bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs=Input(shape=(None,num_encoder_tokens))\n",
    "encoder=LSTM(latent_dim,return_state=True)\n",
    "encoder_outputs,state_h,state_c=encoder(encoder_inputs)\n",
    "encoder_states=[state_h,state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cc4e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs=Input(shape=(None,num_decoder_tokens))\n",
    "decoder_lstm=LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "decoder_outputs,_, _=decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "decoder_dense=Dense(num_decoder_tokens,activation='softmax')\n",
    "decoder_outputs=decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8bf12b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 25s 177ms/step - loss: 1.4888 - accuracy: 0.7070 - val_loss: 1.0206 - val_accuracy: 0.7145\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 23s 187ms/step - loss: 0.8729 - accuracy: 0.7634 - val_loss: 0.8297 - val_accuracy: 0.7710\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 22s 177ms/step - loss: 0.6713 - accuracy: 0.8128 - val_loss: 0.6848 - val_accuracy: 0.8046\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 23s 187ms/step - loss: 0.5780 - accuracy: 0.8329 - val_loss: 0.6208 - val_accuracy: 0.8215\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.5234 - accuracy: 0.8474 - val_loss: 0.5822 - val_accuracy: 0.8317\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 26s 206ms/step - loss: 0.4857 - accuracy: 0.8574 - val_loss: 0.5495 - val_accuracy: 0.8399\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 23s 183ms/step - loss: 0.4574 - accuracy: 0.8653 - val_loss: 0.5306 - val_accuracy: 0.8447\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.4362 - accuracy: 0.8704 - val_loss: 0.5133 - val_accuracy: 0.8488\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.4112 - accuracy: 0.8774 - val_loss: 0.5055 - val_accuracy: 0.8521\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 23s 185ms/step - loss: 0.3916 - accuracy: 0.8834 - val_loss: 0.4898 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.3765 - accuracy: 0.8868 - val_loss: 0.4787 - val_accuracy: 0.8589\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.3575 - accuracy: 0.8927 - val_loss: 0.4747 - val_accuracy: 0.8618\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 23s 187ms/step - loss: 0.3416 - accuracy: 0.8974 - val_loss: 0.4662 - val_accuracy: 0.8642\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 24s 196ms/step - loss: 0.3339 - accuracy: 0.8996 - val_loss: 0.4604 - val_accuracy: 0.8657\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.3149 - accuracy: 0.9054 - val_loss: 0.4580 - val_accuracy: 0.8672\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 24s 190ms/step - loss: 0.3021 - accuracy: 0.9088 - val_loss: 0.4519 - val_accuracy: 0.8698\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.2928 - accuracy: 0.9120 - val_loss: 0.4510 - val_accuracy: 0.8699\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 0.2830 - accuracy: 0.9147 - val_loss: 0.4500 - val_accuracy: 0.8710\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 23s 187ms/step - loss: 0.2702 - accuracy: 0.9187 - val_loss: 0.4547 - val_accuracy: 0.8701\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.2594 - accuracy: 0.9216 - val_loss: 0.4526 - val_accuracy: 0.8715\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 23s 188ms/step - loss: 0.2522 - accuracy: 0.9239 - val_loss: 0.4572 - val_accuracy: 0.8723\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.2408 - accuracy: 0.9270 - val_loss: 0.4517 - val_accuracy: 0.8735\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 24s 190ms/step - loss: 0.2304 - accuracy: 0.9308 - val_loss: 0.4530 - val_accuracy: 0.8730\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.2247 - accuracy: 0.9323 - val_loss: 0.4535 - val_accuracy: 0.8740\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.2144 - accuracy: 0.9352 - val_loss: 0.4591 - val_accuracy: 0.8735\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 24s 190ms/step - loss: 0.2083 - accuracy: 0.9369 - val_loss: 0.4603 - val_accuracy: 0.8742\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 24s 190ms/step - loss: 0.1982 - accuracy: 0.9398 - val_loss: 0.4631 - val_accuracy: 0.8752\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.1943 - accuracy: 0.9409 - val_loss: 0.4659 - val_accuracy: 0.8746\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.1875 - accuracy: 0.9433 - val_loss: 0.4712 - val_accuracy: 0.8748\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 24s 196ms/step - loss: 0.1811 - accuracy: 0.9453 - val_loss: 0.4785 - val_accuracy: 0.8743\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 24s 196ms/step - loss: 0.1742 - accuracy: 0.9471 - val_loss: 0.4826 - val_accuracy: 0.8743\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.1693 - accuracy: 0.9488 - val_loss: 0.4926 - val_accuracy: 0.8731\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.1624 - accuracy: 0.9508 - val_loss: 0.4909 - val_accuracy: 0.8745\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.1554 - accuracy: 0.9525 - val_loss: 0.4936 - val_accuracy: 0.8749\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.1507 - accuracy: 0.9542 - val_loss: 0.5005 - val_accuracy: 0.8744\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.1466 - accuracy: 0.9556 - val_loss: 0.5073 - val_accuracy: 0.8746\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.1412 - accuracy: 0.9571 - val_loss: 0.5185 - val_accuracy: 0.8724\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.1368 - accuracy: 0.9585 - val_loss: 0.5196 - val_accuracy: 0.8734\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.1334 - accuracy: 0.9595 - val_loss: 0.5194 - val_accuracy: 0.8741\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 23s 188ms/step - loss: 0.1279 - accuracy: 0.9611 - val_loss: 0.5217 - val_accuracy: 0.8735\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.1244 - accuracy: 0.9620 - val_loss: 0.5280 - val_accuracy: 0.8732\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.1199 - accuracy: 0.9635 - val_loss: 0.5383 - val_accuracy: 0.8736\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.1177 - accuracy: 0.9642 - val_loss: 0.5429 - val_accuracy: 0.8732\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 25s 204ms/step - loss: 0.1130 - accuracy: 0.9653 - val_loss: 0.5452 - val_accuracy: 0.8733\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.1100 - accuracy: 0.9661 - val_loss: 0.5588 - val_accuracy: 0.8722\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.1081 - accuracy: 0.9667 - val_loss: 0.5596 - val_accuracy: 0.8727\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.1028 - accuracy: 0.9686 - val_loss: 0.5702 - val_accuracy: 0.8716\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.1004 - accuracy: 0.9690 - val_loss: 0.5733 - val_accuracy: 0.8718\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 24s 190ms/step - loss: 0.0965 - accuracy: 0.9700 - val_loss: 0.5819 - val_accuracy: 0.8717\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.0937 - accuracy: 0.9709 - val_loss: 0.5880 - val_accuracy: 0.8719\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.0916 - accuracy: 0.9717 - val_loss: 0.5993 - val_accuracy: 0.8707\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.0901 - accuracy: 0.9723 - val_loss: 0.5995 - val_accuracy: 0.8714\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.0874 - accuracy: 0.9729 - val_loss: 0.6067 - val_accuracy: 0.8704\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.0852 - accuracy: 0.9735 - val_loss: 0.6115 - val_accuracy: 0.8712\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.0830 - accuracy: 0.9739 - val_loss: 0.6138 - val_accuracy: 0.8713\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 22s 175ms/step - loss: 0.0811 - accuracy: 0.9744 - val_loss: 0.6203 - val_accuracy: 0.8718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "125/125 [==============================] - 22s 180ms/step - loss: 0.0786 - accuracy: 0.9752 - val_loss: 0.6244 - val_accuracy: 0.8721\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 29s 235ms/step - loss: 0.0768 - accuracy: 0.9755 - val_loss: 0.6287 - val_accuracy: 0.8709\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 28s 220ms/step - loss: 0.0744 - accuracy: 0.9764 - val_loss: 0.6323 - val_accuracy: 0.8716\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 28s 226ms/step - loss: 0.0724 - accuracy: 0.9771 - val_loss: 0.6454 - val_accuracy: 0.8701\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.0703 - accuracy: 0.9778 - val_loss: 0.6566 - val_accuracy: 0.8702\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 28s 223ms/step - loss: 0.0693 - accuracy: 0.9781 - val_loss: 0.6537 - val_accuracy: 0.8696\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 27s 212ms/step - loss: 0.0669 - accuracy: 0.9787 - val_loss: 0.6602 - val_accuracy: 0.8697\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 22s 180ms/step - loss: 0.0664 - accuracy: 0.9788 - val_loss: 0.6665 - val_accuracy: 0.8695\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.0642 - accuracy: 0.9795 - val_loss: 0.6682 - val_accuracy: 0.8701\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 0.0631 - accuracy: 0.9797 - val_loss: 0.6778 - val_accuracy: 0.8692\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.0609 - accuracy: 0.9803 - val_loss: 0.6779 - val_accuracy: 0.8692\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 26s 210ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 0.6865 - val_accuracy: 0.8681\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 28s 222ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.6918 - val_accuracy: 0.8696\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 30s 239ms/step - loss: 0.0572 - accuracy: 0.9813 - val_loss: 0.6907 - val_accuracy: 0.8701\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.7041 - val_accuracy: 0.8683\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 26s 205ms/step - loss: 0.0545 - accuracy: 0.9824 - val_loss: 0.7011 - val_accuracy: 0.8700\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.0549 - accuracy: 0.9820 - val_loss: 0.7076 - val_accuracy: 0.8695\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.0537 - accuracy: 0.9824 - val_loss: 0.7067 - val_accuracy: 0.8703\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.0519 - accuracy: 0.9828 - val_loss: 0.7140 - val_accuracy: 0.8696\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.0514 - accuracy: 0.9831 - val_loss: 0.7230 - val_accuracy: 0.8691\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.0502 - accuracy: 0.9835 - val_loss: 0.7256 - val_accuracy: 0.8693\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 24s 188ms/step - loss: 0.0492 - accuracy: 0.9837 - val_loss: 0.7254 - val_accuracy: 0.8687\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 24s 190ms/step - loss: 0.0489 - accuracy: 0.9837 - val_loss: 0.7309 - val_accuracy: 0.8686\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 24s 190ms/step - loss: 0.0474 - accuracy: 0.9842 - val_loss: 0.7411 - val_accuracy: 0.8688\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.0474 - accuracy: 0.9841 - val_loss: 0.7302 - val_accuracy: 0.8692\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.0464 - accuracy: 0.9843 - val_loss: 0.7441 - val_accuracy: 0.8687\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 0.7449 - val_accuracy: 0.8686\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.0447 - accuracy: 0.9849 - val_loss: 0.7495 - val_accuracy: 0.8689\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.0444 - accuracy: 0.9847 - val_loss: 0.7491 - val_accuracy: 0.8693\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.0443 - accuracy: 0.9848 - val_loss: 0.7573 - val_accuracy: 0.8684\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.0430 - accuracy: 0.9852 - val_loss: 0.7627 - val_accuracy: 0.8688\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 23s 188ms/step - loss: 0.0426 - accuracy: 0.9855 - val_loss: 0.7715 - val_accuracy: 0.8672\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.0419 - accuracy: 0.9856 - val_loss: 0.7612 - val_accuracy: 0.8681\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 23s 188ms/step - loss: 0.0417 - accuracy: 0.9856 - val_loss: 0.7673 - val_accuracy: 0.8682\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.0403 - accuracy: 0.9859 - val_loss: 0.7781 - val_accuracy: 0.8677\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.0402 - accuracy: 0.9859 - val_loss: 0.7802 - val_accuracy: 0.8682\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.0398 - accuracy: 0.9861 - val_loss: 0.7744 - val_accuracy: 0.8683\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 24s 190ms/step - loss: 0.0398 - accuracy: 0.9862 - val_loss: 0.7830 - val_accuracy: 0.8687\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.0395 - accuracy: 0.9862 - val_loss: 0.7848 - val_accuracy: 0.8672\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.0388 - accuracy: 0.9861 - val_loss: 0.7853 - val_accuracy: 0.8683\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.0381 - accuracy: 0.9866 - val_loss: 0.7861 - val_accuracy: 0.8687\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 23s 188ms/step - loss: 0.0382 - accuracy: 0.9863 - val_loss: 0.7916 - val_accuracy: 0.8677\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.0373 - accuracy: 0.9867 - val_loss: 0.7952 - val_accuracy: 0.8686\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 22s 180ms/step - loss: 0.0375 - accuracy: 0.9863 - val_loss: 0.7973 - val_accuracy: 0.8680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf19e49670>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit([encoder_input_data,decoder_input_data],decoder_target_data,batch_size =batch_size,epochs=epochs,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a17a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b278b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model=Model(encoder_inputs,encoder_states)\n",
    "decoder_state_input_h=Input(shape=(latent_dim,))\n",
    "decoder_state_input_c=Input(shape=(latent_dim,))\n",
    "decoder_states_inputs=[decoder_state_input_h,decoder_state_input_c]\n",
    "decoder_ouputs,state_h,state_c=decoder_lstm(decoder_inputs,initial_state=decoder_states_inputs)\n",
    "decoder_states=[state_h,state_c]\n",
    "decoder_ouputs=decoder_dense(decoder_outputs)\n",
    "decoder_model=Model([decoder_inputs]+decoder_states_inputs,[decoder_outputs]+decoder_states)\n",
    "\n",
    "reverse_input_char_index=dict((i,char) for char,i in input_token_index.items())\n",
    "reverse_target_char_index=dict((i,char) for char,i in target_token_index.items())\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value=encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq =np.zeros((1,1,num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']]=1.\n",
    "    \n",
    "    stop_condition=False\n",
    "    decoded_sentence=''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c=decoder_model.predict(\n",
    "        [target_seq]+states_value)\n",
    "        \n",
    "        sampled_token_index=np.argmax(output_token[0,-1, :])\n",
    "        sampled_char=reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence+=sampled_char\n",
    "        \n",
    "        #Exit Condition:either hit max length or find stop charater\n",
    "        if(sampled_char== '\\n' or len(decoded_sentence)>max_decoder_seq_length):\n",
    "            stop_condition=True\n",
    "        #update the target sequence(of length 1)\n",
    "        target_seq=np.zeros((1,1,num_decoder_tokens))\n",
    "        target_seq[0,0,sampled_token_index]=1\n",
    "        \n",
    "        #update states\n",
    "        states_value=[h,c]\n",
    "    return decoded_sentence\n",
    "for seq_index in range(100):\n",
    "    input_seq=encoder_input_data[seq_index: seq_index+1]\n",
    "    decoded_sentence=decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:',input_texts[seq_index])\n",
    "    print('Decoded sentence:',decoded_sentence)\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
